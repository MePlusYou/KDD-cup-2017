{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 Data_preprocessing.ipynb的基础上做的改变\n",
    "1. 将72个20分钟段特征去掉,改成24个小时段+一个小时的3个20分钟段组合\n",
    "2. 增加天气数据\n",
    " - 天气中风向的异常值99107用他前一个风向与后一个风向的平均值代替"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 读取测试训练的t3,t4,t5,t6.t7,合并训练测试的t7生成天气数据\n",
    "2. 按照20分钟时间窗口得到 t5_train,t6_train,t5_test_2h_ago,t6_testt_2h_ago\n",
    "3. t5_test_2h_ago,t6_testt_2h_ago,时间窗口加2小时去掉标签,得到t5_test,t6_test\n",
    "4. 按照时间日期给t5_train,t6_train,t5_test,t6_test,加特征是否假期,星期几,几点钟,在那个20分钟段\n",
    "5. 按照时间日期增加天气数据并fillna\n",
    "6. 清洗t4,t5得每条路线的,宽度长度岔路数,t5_train,t5_test按照Intersection 和 Tollgates 添加路途宽度长度岔路数特征\n",
    "7. t5_train,t6_train,t5_test,t6_test数据格式修改到要求的格式,保存到csv文件中\n",
    "8. 查看文件发现并修改一些问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "t3 = pd.read_csv('E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\training\\links (table 3).csv')\n",
    "t4 = pd.read_csv('E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\training\\\\routes (table 4).csv')\n",
    "t5_train = pd.read_csv('E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\training\\\\trajectories(table 5)_training.csv')\n",
    "t6_train = pd.read_csv(\"E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\training\\\\volume(table 6)_training.csv\")\n",
    "t6_test_2h_ago = pd.read_csv(\"E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\testing_phase1\\\\volume(table 6)_test1.csv\")\n",
    "t5_test_2h_ago = pd.read_csv(\"E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\testing_phase1\\\\trajectories(table 5)_test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rel_humidity</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.4</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>225.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>26.4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000.5</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>187.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>6</td>\n",
       "      <td>998.9</td>\n",
       "      <td>1003.7</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>31.7</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>9</td>\n",
       "      <td>998.7</td>\n",
       "      <td>1003.5</td>\n",
       "      <td>244.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>31.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>12</td>\n",
       "      <td>999.7</td>\n",
       "      <td>1004.5</td>\n",
       "      <td>222.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date  hour  pressure  sea_pressure  wind_direction  \\\n",
       "0      0  2016-07-01     0    1000.4        1005.3           225.0   \n",
       "1      1  2016-07-01     3    1000.5        1005.3           187.0   \n",
       "2      2  2016-07-01     6     998.9        1003.7           212.0   \n",
       "3      3  2016-07-01     9     998.7        1003.5           244.0   \n",
       "4      4  2016-07-01    12     999.7        1004.5           222.0   \n",
       "\n",
       "   wind_speed  temperature  rel_humidity  precipitation  \n",
       "0         2.1         26.4          94.0            0.0  \n",
       "1         2.7         29.0          76.0            0.0  \n",
       "2         2.9         31.7          67.0            0.0  \n",
       "3         2.7         31.6          59.0            0.0  \n",
       "4         1.3         29.9          68.0            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read table 7\n",
    "t7 = pd.read_csv('E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\\\dataSets\\\\training\\weather (table 7)_training_update.csv')\n",
    "t71 =pd.read_csv(\"E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\dataSets\\\\testing_phase1\\weather (table 7)_test1.csv\")\n",
    "t7 = t7.append(t71).reset_index()\n",
    "del t71\n",
    "t7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 修改风向\n",
    "for i, row in t7.iterrows():\n",
    "    if row['wind_direction']== 999017.0:\n",
    "        last = t7.loc[i-1,'wind_direction']\n",
    "        nest = t7.loc[i+1,'wind_direction']\n",
    "        t7.loc[i, 'wind_direction'] = (last + nest)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 按照时间窗口重组数据: http://stackoverflow.com/questions/36914892/python-how-to-group-pandas-data-frame-in-a-certain-time-window\n",
    "t5_train['starting_time'] =  pd.to_datetime(t5_train['starting_time'] , format='%Y-%m-%d %H:%M:%S')\n",
    "t5_train = t5_train.set_index(['starting_time'])\n",
    "\n",
    "t5_train = t5_train.groupby([pd.TimeGrouper('20Min'), 'intersection_id', 'tollgate_id']).travel_time.mean()\\\n",
    "       .reset_index().rename(columns = {'travel_time':'avg_travel_time'})\n",
    "    \n",
    "t5_test_2h_ago['starting_time'] =  pd.to_datetime(t5_test_2h_ago['starting_time'] , format='%Y-%m-%d %H:%M:%S')\n",
    "t5_test_2h_ago = t5_test_2h_ago.set_index(['starting_time'])\n",
    "\n",
    "t5_test_2h_ago = t5_test_2h_ago.groupby([pd.TimeGrouper('20Min'), 'intersection_id', 'tollgate_id']).travel_time.mean()\\\n",
    "       .reset_index().rename(columns = {'travel_time':'avg_travel_time'})\n",
    "    \n",
    "    \n",
    "t6_train['time'] =  pd.to_datetime(t6_train['time'] , format='%Y-%m-%d %H:%M:%S')\n",
    "t6_train = t6_train.set_index(['time'])\n",
    "\n",
    "# 车流量\n",
    "t6_train = t6_train.groupby([pd.TimeGrouper('20Min'), 'tollgate_id', 'direction']).size()\\\n",
    "       .reset_index().rename(columns = {0:'volume'})\n",
    "    \n",
    "    \n",
    "t6_test_2h_ago['time'] =  pd.to_datetime(t6_test_2h_ago['time'] , format='%Y-%m-%d %H:%M:%S')\n",
    "t6_test_2h_ago = t6_test_2h_ago.set_index(['time'])\n",
    "\n",
    "# 车流量\n",
    "t6_test_2h_ago = t6_test_2h_ago.groupby([pd.TimeGrouper('20Min'), 'tollgate_id', 'direction']).size()\\\n",
    "       .reset_index().rename(columns = {0:'volume'})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先将t5_test_2h_ago补充完整\n",
    "# 导入标准的提交案例\n",
    "t_origin = pd.read_csv('E:\\Competetion\\KDD-cup-2017\\KDD_OFFICIAL_DATA\\\\\\submission_sample_travelTime.csv')\n",
    "time_window_all = t_origin[(t_origin['intersection_id']=='A') & (t_origin['tollgate_id']==2)]['time_window']\n",
    "# 取出提交结果中的所有time_window\n",
    "time_windows = []\n",
    "for t in time_window_all:\n",
    "    time1 = t.split(',')[0][1:]\n",
    "    time1 = pd.to_datetime(time1, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    time1 = time1 - pd.DateOffset(hours=2)\n",
    "    time_windows.append(time1)\n",
    "time_windows = pd.Series(time_windows).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把所有的id组合取出来\n",
    "ids = []\n",
    "for i in range(t_origin.shape[0]):\n",
    "    inter_id = t_origin.loc[i]['intersection_id']\n",
    "    toll_id = t_origin.loc[i]['tollgate_id']\n",
    "    item = (inter_id, toll_id)\n",
    "    if item not in ids:\n",
    "        ids.append(item)\n",
    "# 用测试集离缺失time_window最近的一个avg_travel_time填补\n",
    "def find_last_time(tabel_test, inter_id, toll_id, time_windows, num):\n",
    "    while num > 0:\n",
    "        try:\n",
    "            travel_time = tabel_test[(tabel_test['starting_time'] == time_windows[num - 1])& (tabel_test['intersection_id']==inter_id) & (tabel_test['tollgate_id']==toll_id)]['avg_travel_time']\n",
    "            return travel_time.values[0]\n",
    "        except Exception,e:\n",
    "            num = num - 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 4)\n",
      "(504, 4)\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "print t5_test_2h_ago.shape\n",
    "for inter_id, toll_id in ids:\n",
    "    t1 = t5_test_2h_ago[(t5_test_2h_ago['intersection_id']==inter_id) & (t5_test_2h_ago['tollgate_id']==toll_id)]['starting_time'].values\n",
    "    m = copy(t5_test_2h_ago[(t5_test_2h_ago['intersection_id']==inter_id) & (t5_test_2h_ago['tollgate_id']==toll_id)].reset_index())\n",
    "    m.drop('index',axis=1,inplace=True)\n",
    "    m = m.loc[0]\n",
    "    for i in range(len(time_windows)):\n",
    "        if time_windows[i] not in t1: \n",
    "            t = time_windows[i]\n",
    "            m['starting_time'] = t\n",
    "            avg_time = find_last_time(t5_test_2h_ago, inter_id, toll_id, time_windows, i)\n",
    "            m['avg_travel_time'] = avg_time\n",
    "            t5_test_2h_ago = t5_test_2h_ago.append(m)\n",
    "print t5_test_2h_ago.shape\n",
    "# 测试通过，全部填补完毕应该为504行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apped 2h前测试数据\n",
    "t5_train= t5_train.append(t5_test_2h_ago).reset_index()\n",
    "t6_train= t6_train.append(t6_test_2h_ago).reset_index()\n",
    "# 增加两小时作为测试数据\n",
    "t5_test_2h_ago['starting_time'] = t5_test_2h_ago['starting_time'] + pd.DateOffset(hours=2)\n",
    "t6_test_2h_ago['time'] = t6_test_2h_ago['time'] + pd.DateOffset(hours=2)\n",
    "# 测试数据\n",
    "t5_test,t6_test =t5_test_2h_ago,t6_test_2h_ago\n",
    "del t5_test_2h_ago,t6_test_2h_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 中秋国庆假期\n",
    "from datetime import datetime\n",
    "start1 = datetime(2016, 9, 15)\n",
    "end1 = datetime(2016, 9, 17)\n",
    "start2 = datetime(2016, 10, 1)\n",
    "end2 = datetime(2016, 10, 7)\n",
    "# 增加开学日期\n",
    "start3 = datetime(2016, 8, 29)\n",
    "end3 = datetime(2016, 9, 2)\n",
    "rng = pd.date_range(start1, end1).append(pd.date_range(start2, end2)).append(pd.date_range(start3, end3))\n",
    "\n",
    "# 是否假期,星期,小时,在那个时间窗口\n",
    "\n",
    "def generateDataTime(X,label):\n",
    "    \n",
    "    # 小时,星期,时间窗口\n",
    "    hour = pd.get_dummies(X[label].dt.hour,prefix='hour_')\n",
    "    weekday = pd.get_dummies(X[label].dt.weekday)\n",
    "    minute= pd.get_dummies(X[label].dt.minute)\n",
    "    # 添加到X\n",
    "    X = pd.concat([X,weekday,hour, minute], axis=1)\n",
    "    # 增加 date hour特征方便与t7配对以添加天气数据\n",
    "    X['date']=X[label].dt.date\n",
    "    X['date'] = X['date'].astype(str)\n",
    "    X['date'] = pd.to_datetime(X['date'], format='%Y-%m-%d')\n",
    "    X['hour']=X[label].dt.hour.astype(int)\n",
    "    # 是否在假期内\n",
    "    date = X[label].dt.date\n",
    "    for i, row in X.iterrows():\n",
    "        X.loc[i, \"holiday\"] = 0\n",
    "        if date.loc[i] in rng: X.loc[i, \"holiday\"] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成包含日期数据的数据\n",
    "t5_test = generateDataTime(t5_test,'starting_time')\n",
    "t6_test = generateDataTime(t6_test,'time')\n",
    "t5_train = generateDataTime(t5_train,'starting_time')\n",
    "t6_train = generateDataTime(t6_train,'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照日期时间添加天气数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t7['date'] = pd.to_datetime(t7['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将hour转变成3小时间隔,然后与天气数据组合\n",
    "def add_weather(df):\n",
    "    for i, row in df.iterrows():\n",
    "        if row['hour'] in [23,0,1]: df.loc[i, \"hour\"] = 0\n",
    "        elif row['hour'] in [2,3,4]: df.loc[i, \"hour\"] = 3 \n",
    "        elif row['hour'] in [5,6,7]: df.loc[i, \"hour\"] = 6         \n",
    "        elif row['hour'] in [8,9,10]: df.loc[i, \"hour\"] = 9         \n",
    "        elif row['hour'] in [11,12,13]: df.loc[i, \"hour\"] = 12         \n",
    "        elif row['hour'] in [14,15,16]: df.loc[i, \"hour\"] = 15         \n",
    "        elif row['hour'] in [17,18,19]: df.loc[i, \"hour\"] = 18         \n",
    "        elif row['hour'] in [20,21,22]: df.loc[i, \"hour\"] = 21\n",
    "    return pd.merge(df,t7,on =['date', 'hour'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5_test = add_weather(t5_test)\n",
    "t6_test = add_weather(t6_test)\n",
    "t5_train =add_weather(t5_train)\n",
    "t6_train = add_weather(t6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 删除不必要的列\n",
    "t5_test = t5_test.drop(['hour','date'],axis=1)\n",
    "t6_test = t6_test.drop(['hour','date'],axis=1)\n",
    "t5_train =t5_train.drop(['index_x','hour','date','index_y'],axis=1)\n",
    "t6_train = t6_train.drop(['index_x','hour','date','index_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 道路信息聚合\n",
    "# 将110,123 变成[110,123] \n",
    "def split(str): return str.split(\",\")\n",
    "t4.link_seq = t4.link_seq.apply(split)\n",
    "\n",
    "# 将数据按link_seq中各link展开\n",
    "rows = []\n",
    "_ = t4.apply(lambda row: [rows.append([row['intersection_id'], row['tollgate_id'], nn]) \n",
    "                         for nn in row.link_seq], axis=1)\n",
    "col = ['intersection_id', 'tollgate_id','link_id']\n",
    "t4_new = pd.DataFrame(rows, columns=col)\n",
    "\n",
    "# pd.merge(t4_new,t3,on = 'link_id',how='left')\n",
    "# 提取每条link的是否有in,out交叉路口\n",
    "t3['cross_in'] = 0\n",
    "t3['cross_out'] = 0\n",
    "\n",
    "for i, row in t3.iterrows():\n",
    "    if ',' in str(row['in_top']):\n",
    "        t3.loc[i, \"cross_in\"] = 1\n",
    "    if ',' in str(row['out_top']):\n",
    "        t3.loc[i, \"cross_out\"] = 1\n",
    "        \n",
    "t3['link_id'] = t3['link_id'].astype(str)\n",
    "t4_new['link_id'] = t4_new['link_id'].astype(str)\n",
    "t4_new = pd.merge(t4_new,t3,on = 'link_id',how='left')\n",
    "t4_new.drop(['in_top','out_top'],axis =1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 聚合t4_new\n",
    "# in out 岔路口数\n",
    "b1 = t4_new[['intersection_id', 'tollgate_id','cross_in']]\\\n",
    "           .groupby(['intersection_id', 'tollgate_id'])\\\n",
    "            .cross_in.sum().reset_index().rename(columns = {'cross_in':'in_link_cross_count'})\n",
    "b2 = t4_new[['intersection_id', 'tollgate_id','cross_out']]\\\n",
    "        .groupby(['intersection_id', 'tollgate_id'])\\\n",
    "        .cross_out.sum().reset_index().rename(columns = {'cross_out':'out_link_cross_count'})\n",
    "road = pd.merge(b1,b2,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "\n",
    "# 路程\n",
    "b1 = t4_new[['intersection_id', 'tollgate_id','length']].groupby(['intersection_id', 'tollgate_id']).length.sum().reset_index()\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "## 车道数1车道2车道3车道4车道的link数，后期考虑：占总路程的比率\n",
    "# 各个路径的link总数\n",
    "b1 = t4_new[['intersection_id', 'tollgate_id']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).size()\\\n",
    "    .reset_index().rename(columns = {0:'link_count'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1,2,3,4车道道路长度\n",
    "b1 = t4_new[t4_new.lanes== 1][['intersection_id', 'tollgate_id','length']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).length.sum()\\\n",
    "    .reset_index().rename(columns = {'length':'1_length'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "# 2车道路长度\n",
    "b1 = t4_new[t4_new.lanes== 2][['intersection_id', 'tollgate_id','length']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).length.sum()\\\n",
    "    .reset_index().rename(columns = {'length':'2_length'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "# 3车道路长度\n",
    "b1 = t4_new[t4_new.lanes== 3][['intersection_id', 'tollgate_id','length']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).length.sum()\\\n",
    "    .reset_index().rename(columns = {'length':'3_length'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "# 4车道路长度\n",
    "b1 = t4_new[t4_new.lanes== 4][['intersection_id', 'tollgate_id','length']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).length.sum()\\\n",
    "    .reset_index().rename(columns = {'length':'4_length'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b1 = t4_new[t4_new.lanes== 1][['intersection_id', 'tollgate_id']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).size()\\\n",
    "    .reset_index().rename(columns = {0:'1_count'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "# 2车道link数\n",
    "b1 = t4_new[t4_new.lanes== 2][['intersection_id', 'tollgate_id']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).size()\\\n",
    "    .reset_index().rename(columns = {0:'2_count'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "# 3车道link数\n",
    "b1 = t4_new[t4_new.lanes== 3][['intersection_id', 'tollgate_id']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).size()\\\n",
    "    .reset_index().rename(columns = {0:'3_count'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "# 4车道link数\n",
    "b1 = t4_new[t4_new.lanes== 4][['intersection_id', 'tollgate_id']]\\\n",
    "       .groupby(['intersection_id', 'tollgate_id']).size()\\\n",
    "    .reset_index().rename(columns = {0:'4_count'})\n",
    "road = pd.merge(road,b1,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "\n",
    "road.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5_test = pd.merge(t5_test,road,on =['intersection_id', 'tollgate_id'] ,how='left')\n",
    "t5_train = pd.merge(t5_train,road,on =['intersection_id', 'tollgate_id'] ,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5_test['end'] = t5_test['starting_time'] + pd.DateOffset(minutes=20)\n",
    "t5_train['end'] = t5_train['starting_time'] + pd.DateOffset(minutes=20)\n",
    "t6_test['end'] = t6_test['time'] + pd.DateOffset(minutes=20)\n",
    "t6_train['end'] = t6_train['time'] + pd.DateOffset(minutes=20)\n",
    "\n",
    "\n",
    "# http://stackoverflow.com/questions/30132282/datetime-to-string-with-series-in-python-pandas\n",
    "def timewindows(X,start,end):\n",
    "    s= X[start].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    e = X[end].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    X['time_window'] = '['+ s +','+ e +')'\n",
    "    return X.drop([start,end],axis =1)\n",
    "\n",
    "\n",
    "t5_test = timewindows(t5_test,'starting_time','end')\n",
    "t5_train = timewindows(t5_train,'starting_time','end')\n",
    "t6_test = timewindows(t6_test,'time','end')\n",
    "t6_train = timewindows(t6_train,'time','end')\n",
    "\n",
    "t5_test = t5_test.set_index(['intersection_id','tollgate_id','time_window'])\n",
    "t5_train = t5_train.set_index(['intersection_id','tollgate_id','time_window'])\n",
    "t6_test = t6_test.set_index(['tollgate_id','time_window', 'direction'])\n",
    "t6_train = t6_train.set_index(['tollgate_id','time_window', 'direction'])\n",
    "\n",
    "t5_testcol,t5_traincol = list(t5_test.columns.values),list(t5_train.columns.values)\n",
    "t6_testcol,t6_traincol = list(t6_test.columns.values),list(t6_train.columns.values)\n",
    "mis_5 =  [x for x in t5_traincol  if x not in t5_testcol]\n",
    "mis_6 =  [x for x in t6_traincol  if x not in t6_testcol]\n",
    "\n",
    "for label in mis_5:\n",
    "    t5_test[label] = 0\n",
    "for label in mis_6:\n",
    "    t6_test[label] = 0\n",
    "    \n",
    "# 调整各列顺序\n",
    "t5_test = t5_test[t5_traincol]\n",
    "t6_test = t6_test[t6_traincol]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill(df):\n",
    "    return df.fillna(df.mean())\n",
    "t5_test = fill(t5_test)\n",
    "t6_test = fill(t6_test)\n",
    "t5_train =fill(t5_train)\n",
    "t6_train =fill(t6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5_test.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\testset_task1_total.csv')\n",
    "t5_train.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\trainset_task1_total.csv')\n",
    "t6_test.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\testset_task2_total.csv')\n",
    "t6_train.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\trainset_task2_total.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修复问题\n",
    "* 发现测试和训练数据时间维度不同\n",
    "* 原因：pd.getdummy()是吧所有可能取值都作为一列，但是测试数据时间的取值范围要比训练集小，顾会少很多列\n",
    "* 办法：补充这些列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5_testcol,t5_traincol = list(t5_test.columns.values),list(t5_train.columns.values)\n",
    "t6_testcol,t6_traincol = list(t6_test.columns.values),list(t6_train.columns.values)\n",
    "mis_5 =  [x for x in t5_traincol  if x not in t5_testcol]\n",
    "mis_6 =  [x for x in t6_traincol  if x not in t6_testcol]\n",
    "\n",
    "for label in mis_5:\n",
    "    t5_test[label] = 0\n",
    "for label in mis_6:\n",
    "    t6_test[label] = 0\n",
    "# 调整各列顺序\n",
    "t5_test = t5_test[t5_traincol]\n",
    "t6_test = t6_test[t6_traincol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t5_test.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\testset_task1_total.csv')\n",
    "t5_train.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\trainset_task1_total.csv')\n",
    "t6_test.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\testset_task2_total.csv')\n",
    "t6_train.to_csv('E:\\Competetion\\KDD-cup-2017\\\\data_pre\\\\trainset_task2_total.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
